# -*- coding: utf-8 -*-
"""House Price Prediction Using Machine learning with Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KOosOAJxHYpcQxEhKXJQ36om6WeEdT5q

Importing The Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_absolute_error

"""importing the Boosten House Price Dataset"""

california_house_price_dataset = sklearn.datasets.fetch_california_housing()

print(california_house_price_dataset)

# coverting the dataset to dataframe with pandas library
california_house_price_dataFrame = pd.DataFrame(california_house_price_dataset.data, columns = california_house_price_dataset.feature_names)

california_house_price_dataFrame.head()

# we have to add the target column to the Dataframe
california_house_price_dataFrame["price"] = california_house_price_dataset.target

california_house_price_dataFrame.head()

california_house_price_dataFrame.shape

# we have to  check missing values
california_house_price_dataFrame.isnull().sum()

#statistical data of the dataset

california_house_price_dataFrame.describe()

"""Relation between the features like Correlation in the dataset"""

correlation_data = california_house_price_dataFrame.corr()

# To understand the correlation we have to construct heatmap

plt.figure(figsize = (10,10))

sns.heatmap(correlation_data, cbar = True , square = True, fmt = '.2f', annot = True, annot_kws = {'size' : 8}, cmap = 'Greens')

"""We have to split the data and target"""

a = california_house_price_dataFrame.drop(["price"], axis = 1)
b = california_house_price_dataFrame["price"]

print(a)
print(b)

# now splitting the data into training data and test data

a_train,a_test,b_train,b_test = train_test_split(a,b, test_size = 0.2 , random_state = 2)

print(a,a_train,a_test)

print(a.shape,a_train.shape,a_test.shape)

"""Training The  Model

XGBoost Regressor --->This is a type decision tree algorithm, its a basically ensemble moodel(we use more than one models).
"""

model = XGBRegressor()

# now we have to train the model with training data

model.fit(a_train,b_train)

"""Prediction on training data

"""

#accuracy on training data

training_data_prediction = model.predict(a_train)

print(training_data_prediction)

"""R squared error



Mean Absolute error
"""

#R squared error
score_1 = metrics.r2_score(b_train, training_data_prediction)

print("R squared error : ", score_1)

# Mean Absolute error

score_2 = metrics.mean_absolute_error(b_train, training_data_prediction)

print(" Mean absolute error : ", score_2)

#accuracy on test data

test_data_prediction = model.predict(a_test)

# We should evaulate the model with test data
#R squared error
score_1 = metrics.r2_score(b_test, test_data_prediction)

print("R squared error : ", score_1)

# Mean Absolute error

score_2 = metrics.mean_absolute_error(b_test, test_data_prediction)

print(" Mean absolute error : ", score_2)

"""Visualizing the actual prices and predicted prices

"""

plt.scatter(b_train,training_data_prediction)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Price")
plt.title("Actual price vs Predicted price")
plt.show()

